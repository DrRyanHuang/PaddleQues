本周主要阅读了 `paddle/cinn/hlir/framework/new_ir_compiler.*` 的相关代码

### 1.
`paddle/pir/core/value.h` 文件下, `::pir::Value` 类抽象出来的目的是什么, 相当于给 `Impl` 套了一层包装? 一般用来保存什么值呢?

```c++
///
/// \brief Value class represents the SSA value in the IR system. This class
/// only provides interfaces, for specific implementation, see Impl class.
///
class IR_API Value {
 public:
  Value() = default;

  Value(const detail::ValueImpl *impl);  // NOLINT

  Value(const Value &other) = default;
```



### 2. Scope 的作用是什么? 为什么 `new_ir_compiler.cc` 要创建 `Scope`

`paddle/cinn/hlir/framework/scope.h`

```c++
std::shared_ptr<Scope> BuildScope(const Target& target,
                                  const ::pir::Program& program) {
  std::unordered_set<::pir::Value> visited;
  auto scope = std::make_shared<Scope>();

  auto create_var = [&](::pir::Value value) {
    if (visited.count(value) > 0) return;
    visited.emplace(value);

    std::string name = CompatibleInfo::ValueName(value);
    auto type_info = value.type().dyn_cast<paddle::dialect::DenseTensorType>();
    auto* var = scope->Var<Tensor>(name);
    auto& tensor = absl::get<Tensor>(*var);

    std::vector<Shape::dim_t> shape;
    for (auto i = 0; i < type_info.dims().size(); ++i) {
      shape.push_back(Shape::dim_t(type_info.dims()[i]));
    }
    tensor->Resize(Shape{shape});
    tensor->set_type(utils::ConvertIRType(type_info.dtype()));
  };

  for (auto it = program.block()->begin(); it != program.block()->end(); ++it) {
    for (auto& oprand : (*it)->operands()) {
      create_var(oprand.source());
    }

    for (auto& result : (*it)->results()) {
      create_var(result);
    }
  }
  return scope;
}
```

### 3. instruction 和 Operation 作用类似, 都是运行时的执行单元, 二者用法上有什么不同呢? 

`NewIRCompiler` 中有 `BuildInstructions` 为什么没有 `Build Operation` 呢?

`paddle/cinn/hlir/framework/instruction.h` 

```c++
/**
 * Instruction is the basic executable element in runtime, it holds a pointer to
 * the JIT-compiled LoweredFunc, and collect the cinn_buffer of the inputs and
 * outputs from the scope, prepare the arguments and finally pass them into the
 * LoweredFunc and execute it.
 */
class Instruction {
 public:
  using infershape_t =
      std::function<void(Scope*, const std::vector<std::string>&)>;

  /**
   * Constructor.
   * @param target The \p target the instruction runs on.
   * @param scope The scope containing all the runtime variables(Tensors and
   * PODs).
   * @param in_args The names of the inputs.
   * @param out_args The names of the outputs.
   * @param infershape The handler of this Instruction to perform shape
   * inference.
   */
```